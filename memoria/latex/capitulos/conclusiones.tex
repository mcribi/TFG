% !TeX root = ../tfg.tex
% !TeX encoding = utf8

\chapter{Conclusiones}
En este trabajo, se ha abordado el problema de la predicción de complicaciones en biopsias de pulmón, un problema novedoso y de interés médico, que en caso de abordarse exitosamente puede suponer un avance importante en el campo de toma de muestras de tejido pulmonar, al anticipar los posibles riesgos que puedan producirse. Para realizar este se ha trabajado, se ha colaborado con un equipo médico del Hospital San Cecilio, el cual ha proporcionado datos etiquetados y conocimiento experto para abordar este problema.

El trabajo se ha abordado desde dos perspectivas: una matemática, en la que se han analizado los fundamentos de las técnicas que se han empleado en el problema a tratar, y una informática, en la que se describen las distintas formas en las que se ha intentado abordar el problema. En los fundamentos teóricos se han analizado conceptos como la teoría de la señal aplicada a imágenes, optimización y fundamentos teóricos del aprendizaje automático, profundo y de métricas de distancia. El problema práctico de la predicción de complicaciones se ha abordado empleando distintas técnicas, tanto de deep learning (en 2 y 3 dimensiones) como de radiómica, pasando también por un análisis de los datos proporcionados, un preprocesamiento adecuada y un post-análisis donde se intentan analizar las decisiones tomadas por los modelos.

Durante buena parte del desarrollo del proyecto, los resultados fueron nulos o claramente insuficientes, hasta el punto de cuestionarnos si el problema era abordable con los recursos disponibles. La progresiva recolección de más datos ayudó a mejorar el rendimiento, pero el avance fue siempre desafiante: al principio sufríamos un marcado desbalance de clases, más tarde se resolvió parcialmente, pero aparecían otros problemas como la ausencia de segmentación o el uso de imágenes de tamaños demasiado grandes. Fue especialmente revelador incluir técnicas de explicabilidad, que nos mostraron que el modelo no se fijaba en las regiones pulmonares relevantes, motivándonos a segmentar y a reducir el tamaño de las imágenes para centrar la atención del modelo en lo importante.

Uno de los mayores avances fue el paso a modelos 3D, ya que las aproximaciones iniciales en 2D no funcionaban de forma efectiva. La combinación de segmentación pulmonar, reducción de tamaño y el procesamiento en 3D permitió extraer características más informativas, aunque incluso así los resultados obtenidos con modelos volumétricos puros (DenseNet121 entrenado desde cero, preentrenado o en versiones híbridas con datos clínicos) quedaron lejos de ser satisfactorios. El preentrenamiento en dominios diferentes o la fusión multimodal con datos clínicos no lograron superar los problemas de sobreajuste ni las limitaciones derivadas del reducido tamaño del conjunto de datos.

Ante estas limitaciones del deep learning, atribuibles en gran medida a la escasez de datos y la complejidad del problema, se decidió explorar estrategias más clásicas. Así, se desarrolló un enfoque basado en radiómica, extrayendo características cuantitativas de los volúmenes para alimentar modelos de aprendizaje automático convencional. Esta estrategia resultó ser significativamente más robusta: incluso sin incluir datos clínicos ni metric learning, la radiómica pura logró resultados notablemente mejores que los modelos volumétricos puros o basados solo en datos tabulares.

La incorporación de datos clínicos aportó una mejora adicional, demostrando el valor predictivo complementario de la información del paciente. Además, el uso de técnicas de metric learning permitió aprender representaciones más discriminativas, alcanzando resultados comparables incluso sin datos clínicos. Finalmente, la combinación de radiómica, datos clínicos y metric learning se consolidó como la mejor estrategia, logrando el mayor rendimiento global con un G-Mean aproximado del 74\% en test. Este resultado demuestra un equilibrio sólido entre sensibilidad y especificidad, validando la efectividad de integrar diferentes fuentes de información y técnicas de aprendizaje.

En conclusión, este trabajo evidencia que el deep learning puro no siempre es la opción más adecuada, especialmente en contextos con datos limitados y problemas clínicos complejos. La estrategia de extraer características radiómicas y aplicar aprendizaje automático clásico se ha mostrado más efectiva en este escenario, ofreciendo una solución más interpretable, menos exigente en datos y con mejor rendimiento final para la tarea de predicción de complicaciones en biopsias pulmonares. El problema abordado, si bien con las últimas aproximaciones se han conseguido mejoras relevantes en los resultados, aún deja un amplio margen de mejora. El problema de predicción de complicaciones en biopsias presenta un gran interés clínico y humano, y por ello se espera que la investigación realizada en este trabajo sirva como base para continuar profundizando en la obtención de modelos aún más efectivos.

\section{Líneas de trabajo futuro}

A partir de los resultados obtenidos y de las limitaciones identificadas durante el desarrollo del proyecto, se plantean varias líneas de trabajo futuro para mejorar el rendimiento del modelo:

\begin{itemize}
    \item \textbf{Abordar la predicción del tipo de complicación}: es una extensión natural del problema actual.  Consistiría en abordar no solo la predicción binaria de complicación o no complicación, sino la clasificación del tipo específico de complicación, formulada como un problema de clasificación multietiqueta. Para ello sería indispensable disponer de más datos, ya que en el dataset actual hay tipos de complicaciones con muy pocos casos (incluso un solo ejemplo), lo que hace inabordable el entrenamiento en este momento.
    \item \textbf{Ajustar la segmentación a estructuras más relevantes dentro del pulmón}: en cuanto al preprocesamiento, se propone avanzar hacia segmentaciones más precisas y orientadas a estructuras anatómicas clave como tumores y vasos sanguíneos. Esto permitiría al modelo centrarse en la información más relevante para la predicción. Además, se sugiere investigar hipótesis clínicas planteadas por los propios especialistas, como la posible relación entre el tamaño de la lesión y el riesgo de complicación (por ejemplo, lesiones más pequeñas podrían implicar mayor dificultad técnica en la biopsia).
    \item \textbf{Aprendizaje federado e integración de datos de distintos hospitales}: pueden permitir entrenar modelos de forma colaborativa entre distintos hospitales sin necesidad de compartir datos sensibles. Esto facilitaría el acceso a conjuntos de datos más grandes y diversos, garantizando al mismo tiempo la privacidad de los pacientes.
    \item \textbf{Análisis del impacto de variables técnicas}, como el modelo de máquina de TC utilizada para las adquisiciones. Diferencias en la resolución o en los parámetros de imagen pueden afectar al rendimiento del modelo, que podría aprender a discriminar entre máquinas en lugar de entre patrones clínicos reales, comprometiendo su capacidad de generalización.
    \item \textbf{Aprendizaje con mecanismos de atención}: se plantea también integrar mecanismos de atención en los modelos para reforzar su capacidad de focalizarse en regiones importantes de la imagen y mejorar la interpretabilidad de las predicciones. Incluso, avanzar en técnicas de explicabilidad será clave para generar confianza clínica y facilitar la validación del sistema en entornos reales.
    \item \textbf{Aproximaciones semisupervisadas}: por último, se propone investigar estrategias semisupervisadas que permitan aprovechar tanto datos de pacientes sanos como datos de pacientes con tumores que no estén etiquetados con las complicaciones en biopsias, lo que permitiría entrenar con una cantidad más abundante de datos.
\end{itemize}

\endinput
%--------------------------------------------------------------------
% FIN DEL CAPÍTULO. 
%--------------------------------------------------------------------
