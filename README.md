# ü´Å TFG: Predicci√≥n de complicaciones en biopsias pulmonares con IA

Este repositorio contiene el desarrollo completo del Trabajo de Fin de Grado (TFG) de **Mar√≠a Cribill√©s P√©rez**, dirigido por **Francisco Herrera Triguero** y **Juan Luis Su√°rez D√≠az**, en el marco del doble grado en Ingenier√≠a Inform√°tica y Matem√°ticas en la Universidad de Granada.

üîó **[P√°gina de resultados con visualizaciones interactivas](https://mariacribilles.github.io/TFG/)**

---

## üß† Resumen del proyecto

El objetivo de este TFG es desarrollar un sistema predictivo capaz de estimar si una biopsia pulmonar guiada por tomograf√≠a computarizada (TC) tendr√° o no complicaciones, utilizando t√©cnicas de inteligencia artificial aplicadas a im√°genes m√©dicas 3D y datos cl√≠nicos tabulares. Se proponen diferentes enfoques basados en Deep Learning, Radi√≥mica y modelos h√≠bridos, y se analizan mediante validaci√≥n cruzada y t√©cnicas de explicabilidad.

---

## üìñ Estructura de la memoria del TFG

### üßÆ Parte te√≥rica

- **Procesamiento de im√°genes y se√±ales**: fundamentos sobre discretizaci√≥n, filtros y convoluciones.
- **Transformada de Fourier**: su papel en el an√°lisis de frecuencias de im√°genes m√©dicas.
- **Radi√≥mica**: extracci√≥n cuantitativa de caracter√≠sticas desde im√°genes.
- **Optimizaci√≥n y aprendizaje autom√°tico**: descenso por gradiente, clasificaci√≥n y funciones de p√©rdida.
- **Deep Learning**: redes convolucionales 2D/3D, preentrenamiento y transferencia.
- **Distance Metric Learning**: aprendizaje de distancias con LMNN y NCA.

### üß™ Parte aplicada

#### Cap√≠tulo 6 ‚Äî Planteamiento
Introducci√≥n cl√≠nica, definici√≥n del problema, descripci√≥n del dataset y contexto √©tico/legal.

#### Cap√≠tulo 7 ‚Äî Preprocesado
- Datos volum√©tricos: normalizaci√≥n, segmentaci√≥n con TotalSegmentator, resize y m√°scaras.
- Datos cl√≠nicos: limpieza, codificaci√≥n, imputaci√≥n y escalado.

#### Cap√≠tulo 8 ‚Äî Modelos DL 2D/3D
- Arquitecturas como DenseNet121 y ResNet3D.
- Validaci√≥n cruzada estratificada (5-fold).
- Fusi√≥n multimodal de imagen + datos cl√≠nicos.

#### Cap√≠tulo 9 ‚Äî Radi√≥mica y ML cl√°sico
- Extracci√≥n con PyRadiomics.
- Modelos cl√°sicos: Random Forest, XGBoost, KNN.
- Aprendizaje de m√©tricas (LMNN, NCA) y fusi√≥n con datos cl√≠nicos.

#### Cap√≠tulo 10 ‚Äî Resultados experimentales
- Comparativa entre enfoques: DL puro, h√≠bridos, y radi√≥micos.
- M√©tricas: Accuracy, F1, TPR, TNR, G-Mean.
- Tablas con resultados por fold y an√°lisis detallado.

#### Cap√≠tulo 11 ‚Äî Explicabilidad (XAI)
- Visualizaci√≥n con **Grad-CAM** para modelos 3D.
- Interpretabilidad con **SHAP** para modelos tabulares y radi√≥micos.

#### Cap√≠tulo 12 ‚Äî Conclusiones
- An√°lisis cr√≠tico de los resultados.
- Limitaciones del dataset.
- L√≠neas futuras: aumentar datos, mejorar segmentaci√≥n, generalizaci√≥n multimodal.

---

## üìÇ Estructura del repositorio
- codigo/: scripts de entrenamiento, validaci√≥n, preprocesado y visualizaci√≥n de modelos deep learning, radi√≥micos y multimodales. Contiene el n√∫cleo del sistema predictivo.

- defensa/: materiales utilizados para la defensa del TFG, como presentaciones, figuras y recursos visuales.

- memoria/latex/: c√≥digo fuente completo en LaTeX de la memoria escrita del TFG, incluyendo figuras, tablas y bibliograf√≠a.

- resultados/: resultados obtenidos durante los experimentos, organizados en carpetas por tipo de modelo (DL3D, multimodal, radi√≥mico, etc.). Incluye m√©tricas, visualizaciones SHAP, mapas Grad-CAM y tablas HTML.

- index.html: p√°gina principal que carga el sitio web generado con GitHub Pages, mostrando los resultados interactivos.

- README.md: este archivo, que documenta el contenido y prop√≥sito del repositorio.

- .gitignore: archivo que especifica qu√© archivos/directorios deben ser ignorados por Git.


---

## üñ•Ô∏è P√°gina de resultados (GitHub Pages)

Puedes explorar visualizaciones, m√©tricas, gr√°ficas y resultados detallados de los experimentos en la siguiente p√°gina:  
üìä **[https://mariacribilles.github.io/TFG/](https://mariacribilles.github.io/TFG/)**

---

## üìå Tecnolog√≠as utilizadas

- üß† **Deep Learning**: PyTorch, MONAI
- üìä **Machine Learning cl√°sico**: scikit-learn, XGBoost, LightGBM
- üìà **Radi√≥mica**: PyRadiomics
- ü´Å **Segmentaci√≥n**: TotalSegmentator
- üéØ **Visualizaci√≥n y XAI**: SHAP, Grad-CAM, Matplotlib, Seaborn


## Resumen

La biopsia pulmonar guiada por tomograf√≠a computarizada (TC) es un procedimiento diagn√≥stico esencial para caracterizar n√≥dulos pulmonares y determinar la presencia de neoplasias. Sin embargo, no est√° exenta de riesgos, presentando complicaciones como hemorragias o neumot√≥rax en un porcentaje significativo de casos. Aunque existen numerosos estudios centrados en la clasificaci√≥n de la benignidad o malignidad de los n√≥dulos, apenas hay investigaciones que analicen la probabilidad de complicaciones antes de realizar la biopsia. Esta carencia motiva la necesidad de herramientas predictivas que permitan anticipar el riesgo y optimizar la selecci√≥n de pacientes.

El presente trabajo propone el desarrollo de un sistema predictivo basado en t√©cnicas de radi√≥mica y aprendizaje profundo para estimar el riesgo de complicaciones en biopsias pulmonares guiadas por TC. Para sustentar el dise√±o del modelo, se estudian en detalle los fundamentos matem√°ticos necesarios, incluyendo el procesamiento de se√±ales m√©dicas, teor√≠a de convoluci√≥n, teor√≠a de radi√≥mica y los conceptos te√≥ricos del aprendizaje autom√°tico y profundo. 

La metodolog√≠a incluye el preprocesamiento de im√°genes volum√©tricas con segmentaci√≥n pulmonar y normalizaci√≥n de intensidades, la extracci√≥n de caracter√≠sticas radi√≥micas, el uso de redes neuronales convolucionales 3D y la integraci√≥n de datos cl√≠nicos tabulares para construir modelos multimodales. Se emplean estrategias como el preentrenamiento (transfer learning), la validaci√≥n cruzada estratificada y el an√°lisis de interpretabilidad (Grad-CAM, SHAP) para garantizar robustez y facilitar la validaci√≥n cl√≠nica.

Los resultados obtenidos muestran que, aunque la idea es prometedora, los modelos de aprendizaje profundo sobre im√°genes 3D presentaron limitaciones para generalizar de forma s√≥lida, probablemente debido al tama√±o reducido y la heterogeneidad del conjunto de datos. Por el contrario, los enfoques cl√°sicos de radi√≥mica ofrecieron resultados m√°s estables. Este trabajo representa as√≠ un primer paso en una l√≠nea de investigaci√≥n novedosa, destacando la necesidad de recopilar m√°s datos y refinar estrategias para mejorar la capacidad predictiva en futuros estudios.

**Palabras clave**: Biopsia pulmonar, Tomograf√≠a computarizada, Aprendizaje profundo, Inteligencia Artificial, Radi√≥mica, Redes neuronales convolucionales, Predicci√≥n de complicaciones, Segmentaci√≥n pulmonar, Datos cl√≠nicos.

## Summary
### Problem Description

Lung cancer remains the leading cause of cancer-related mortality worldwide, responsible for over 1.8 million deaths annually. Despite advances in low-dose CT screening enabling earlier detection of lesions, five-year survival rates remain limited due to late diagnoses in advanced stages. To confirm suspicion and characterize tumor subtype, CT-guided lung biopsy is essential. While minimally invasive, this procedure carries inherent risks, the most common being pneumothorax and pulmonary hemorrhage, with incidence rates of up to 22\% and 7\%, respectively. The severity of these complications varies from mild to severe and depends on multiple factors, including lesion location and size, needle path length, pulmonary parenchyma structure, and operator experience.

Currently, risk estimation prior to biopsy relies primarily on the subjective judgment of the interventional radiologist, who qualitatively assesses imaging and patient characteristics. There are no standardized clinical tools or quantitative predictive models that provide personalized, pre-procedural risk estimates. This gap limits the ability to plan preventive measures, tailor procedural techniques, or consider alternative diagnostic strategies for high-risk cases. Investigating the feasibility of developing a system to predict complication risk in lung biopsies using clinical and imaging data is therefore especially relevant.

This project frames the problem as a binary classification task aimed at predicting whether a patient will experience a complication after biopsy, combining structured clinical data and volumetric CT imaging. The goal is to equip clinicians with an objective, personalized risk assessment tool to improve patient safety and optimize medical resources. Beyond its immediate clinical relevance, this research is highly innovative, as there is virtually no prior work in the literature specifically addressing complication prediction in lung biopsies using AI techniques. This absence of references poses additional challenges, such as designing preprocessing, modeling, and validation strategies from scratch, but it also underscores the importance and potential impact of the proposal.

### Mathematical Framework

Developing an AI-based predictive system for anticipating complications in lung biopsies requires a solid theoretical foundation that blends mathematical and computational principles. From a mathematical perspective, medical images can be studied as functions carrying complex anatomical information. Transforms, such as the Fourier transform, enable analysis of the frequency components of these signals, facilitating filtering and enhancement of relevant features. Convolution operations are fundamental for image processing, allowing hierarchical extraction of local patterns. This concept underpins convolutional neural networks, which automatically learn these filters during training to identify discriminative features.

Radiomics leverages these mathematical principles to extract quantitative features from medical images. Using first-order statistics and texture metrics derived from co-occurrence matrices, radiomics generates numerical descriptors that summarize imaging information, capturing subtle patterns potentially linked to higher complication risk. This systematic feature extraction aims to overcome the inherent subjectivity of human visual assessment.

Mathematical optimization is another essential pillar in training machine learning models. The training process is formulated as the minimization of a loss function quantifying the discrepancy between model predictions and actual outcomes. Methods such as gradient descent and its stochastic variants allow efficient adjustment of millions of parameters. The backpropagation algorithm enables efficient calculation of partial derivatives, supporting iterative weight updates in the network.

Supervised machine learning provides the framework for addressing complication risk prediction as a binary classification problem. This approach requires labeled data indicating whether a complication occurred following biopsy and uses these examples to learn a model that generalizes to new cases. Evaluation metrics are particularly important in clinical contexts with significant class imbalance. Accuracy can be misleading when the majority class dominates, so more informative measures like the F1-score are used, along with sensitivity and specificity to assess detection of positives and negatives separately, and the G-Mean, which combines both to evaluate performance in imbalanced scenarios.

###  Practical Approach and Experimentation

This study relied on two main types of data: volumetric chest CT scans and structured clinical data for each patient. For the CT volumes, extensive preprocessing was performed, including intensity normalization to Hounsfield Units using a lung window. This step limited and rescaled intensities to highlight the pulmonary parenchyma, removing extreme values from irrelevant structures like bone or extrapulmonary air. Additionally, lung segmentation was performed using the TotalSegmentator tool to generate precise masks, effectively isolating the anatomical region of interest and reducing input noise. The segmented and normalized volumes were then resized to consistent dimensions to ensure sample homogeneity and facilitate processing in 3D convolutional networks.

Clinical tabular data also required careful cleaning and normalization. The original dataset contained heterogeneous variables, both categorical and numerical, with incomplete or inconsistent records. The data were curated through imputation or removal of missing values, categorical encoding, and numerical scaling. This process ensured a harmonized clinical dataset ready for machine learning, supporting integration with imaging-derived features in subsequent experiments.

A key preprocessing step was lung segmentation, performed with TotalSegmentator to produce accurate lung masks in each CT volume. This allowed effective isolation of the target anatomy while reducing unnecessary noise and variability in the model.

For the modeling phase, a 3D-adapted DenseNet121 was implemented and trained using MONAI and PyTorch. Stratified five-fold cross-validation served as the primary validation method to assess model performance robustly. To improve generalization with limited data, a strategy of pretraining on similar tasks followed by fine-tuning on the specific problem set was applied. This approach enabled transfer of previously acquired knowledge and its adaptation to predicting complication risk in lung biopsies.

In parallel, an alternative radiomics-based approach was developed. Quantitative features were extracted from the segmented volumes using PyRadiomics, including statistical and textural descriptors of the pulmonary parenchyma. These features were combined with patient clinical data and used as inputs for traditional machine learning models such as LightGBM. This pipeline enabled comparison of direct deep learning with a more classical feature-extraction approach.

During experimentation, multimodal integration techniques were applied to combine clinical data with imaging-derived information, enriching the system's predictive context. Additionally, interpretability tools such as Grad-CAM were used to visualize CT regions most influential in deep model predictions, while SHAP values analyzed the impact of each clinical or radiomic variable in classic models. This interpretability was crucial to validate results and ensure potential clinical applicability.

Experiments showed progressive performance improvements thanks to careful preprocessing, precise segmentation, and the use of pretraining and fine-tuning strategies. However, purely 3D deep learning models exhibited notable limitations, with less stable and generalizable results likely due to the task‚Äôs complexity and the small dataset size. In contrast, radiomics-based strategies involving systematic feature extraction and analysis via classic machine learning and deep metric learning delivered more consistent, robust results. These findings suggest that while the developed system represents an important first step toward personalized risk prediction, there remains substantial room for improvement in future work.

